#colnames(vvv)
# head(vvv)
library(ggplot2)
#  vvv<-filterCells(scData_prechrom,minimumSegments = minimumSegments)
#print(
graphCNVDistribution(vv2)
print(ggplot(vv2  %>% gather(Cell,Density,ends_with(scCNVCaller$cellSuffix)),aes(chrom,Density))+geom_violin(scale="width",trim=FALSE) +
theme(axis.text.x=element_text(angle=-90,vjust = 0.5,hjust = 0, color = "#000000"),
axis.text.y=element_text(color="#000000"),
axis.line.x.bottom = element_line(colour="#000000"),
axis.line.y.left =  element_line(colour="#000000"),
panel.background = element_rect(fill="#ffffff"),
plot.background = element_rect(color="#ffffff",fill="#ffffff")) +
xlab("Segment"))
graphCNVDistribution(vv2)
median_iqr <- computeCenters(vv2,summaryFunction=summaryFunction)
#   view(median_iqr[[1]])
#for Nizar samples
#deltaMean was 0.1
#change SD back to 0.1 and cutoff to 1.0 (or 0.7)
#candidate_cnvs<-identifyCNVClusters(vv2,median_iqr,useDummyCells = TRUE,propDummy=0.25,minMix=0.15,deltaMean = 0.4,deltaBIC2 = 50, subsetSize=500,fakeCellSD = 0.20, uncertaintyCutoff = 0.45,summaryFunction=summaryFunction)
#candidate_cnvs<-identifyCNVClusters(vv2,median_iqr,useDummyCells = FALSE,propDummy=0.25,minMix=0.15,deltaMean = 0.4,deltaBIC2 = 50, subsetSize=800,fakeCellSD = 0.10, uncertaintyCutoff = 0.45,summaryFunction=summaryFunction)
library(stringr)
for (i in 5)
{
for (j in 6)
{
#reduced minimum mixing proportion
for (k in 1)
{
#change uncertainty cutoff from 055 to 075
#candidate_cnvs<-identifyCNVClusters(vv2,median_iqr,useDummyCells = TRUE,propDummy=0.05*i,minMix=0.01,deltaMean = 0.03,deltaBIC2 = 50, subsetSize=2000,fakeCellSD = 0.04*j, uncertaintyCutoff = 0.55,summaryFunction=summaryFunction,maxClust = 4,mergeCutoff = 5)
candidate_cnvs<-identifyCNVClusters(vv2,median_iqr,useDummyCells = TRUE,propDummy=0.40,minMix=0.01,deltaMean = 0.03,deltaBIC2 = 50, subsetSize=1000,fakeCellSD = 0.24, uncertaintyCutoff = 0.55,summaryFunction=summaryFunction,maxClust = 4,mergeCutoff = 5)
#candidate_cnvs[[2]]
candidate_cnvs
#some don't need dummy cells
candidate_cnvs_clean<-clusterCNV(initialResultList = candidate_cnvs,medianIQR = candidate_cnvs[[3]],minDiff=1.5) #= 0.3*k)
candidate_cnvs_clean
#range(candidate_cnvs_clean[[1]]$chr10p)
#cell assignments
# asdf<-candidate_cnvs_clean[[1]] %>% filter(str_detect(Cells,"X",negate=TRUE))  %>% gather(Chrom,Cluster,starts_with("chr")) %>% group_by(Chrom) %>% summarise(nclust=max(Cluster))
# asdf$Chrom[which(asdf$nclust>1)]
#view(asdf)
# cc<-candidate_cnvs_clean[[1]] %>% filter(str_detect(Cells,"X",negate=TRUE))  %>% gather(Chrom,Cluster,starts_with("chr")) %>% select(-Cells) %>% filter(Cluster!=0) %>% group_by(Chrom,Cluster) %>% summarise(counts=n())
# view(cc)
#%>% mutate(Chrom_c=str_c(Chrom,Cluster,sep="_")) %>% select(-Chrom, Cluster)
#remove ones with minimum # in smaller cluster?
#TODO: update code in package with new version of this function
#CAVEAT: removing the ones with only one
# final_cnv_list_c<-annotateCNV3(candidate_cnvs_clean,saveOutput=TRUE,outputSuffix = sprintf(fmt="_2_nolog_test%d_0_05_sd_0.04_%d_mindiff_0.3x%d",i,j,k),minCutoff = 50)
# scaledMatrix = vv2,
#final_cnv_list_c[[1]]
final_cnv_list_c<-annotateCNV3(candidate_cnvs_clean, saveOutput=TRUE,outputSuffix = sprintf(fmt="_2_nolog_test%d_0_05_sd_0.04_%d_mindiff_0.3x%d_a1_%d_b1_%d",i,j,k,a1,b1)) # ,minCutoff = 50)
#smoothedList <- smoothClusters("~/p7_clusters.csv",final_cnv_list_c,percentPositive = 0.3)
#write.csv(x=smoothedList,file="~/p7_smooth.csv",quote=FALSE,row.names = FALSE) #,header=TRUE)
#
}
}
}
res_loss<-getLOHRegions(scData_k_norm_cp2,diffThreshold = 0.25,lossCutoff = -0.75,minLength = 2e6,minSeg=2,targetFun=IQR,signalBoost=1,lossCutoffCells = 50,lossCutoffReads = 75,quantileLimit=0.5)
dev.off()
res_loss<-getLOHRegions(scData_k_norm_cp2,diffThreshold = 0.25,lossCutoff = -0.75,minLength = 2e6,minSeg=2,targetFun=IQR,signalBoost=1,lossCutoffCells = 50,lossCutoffReads = 75,quantileLimit=0.5)
res_loss
res_loss[[1]]
res_loss<-getLOHRegions(scData_k_norm_cp2,diffThreshold = 0.25,lossCutoff = -1,minLength = 2e6,minSeg=2,targetFun=IQR,signalBoost=1,lossCutoffCells = 150,lossCutoffReads = 500,quantileLimit=0.3)
res_loss[[1]]
res_loss[[1]]
write.table(x=res_loss[[1]],file=str_c(locPrefix,outPrefix,"_merge","_loss_new.csv"),quote=FALSE,row.names = FALSE,sep=",")
write.table(x=res_loss[[1]],file=str_c("~/",outPrefix,"_merge","_loss_new.csv"),quote=FALSE,row.names = FALSE,sep=",")
write.table(x=res_loss[[1]],file=str_c("~/","p1","_merge","_loss_new.csv"),quote=FALSE,row.names = FALSE,sep=",")
library(edgeR)
library(CONICSmat)
#now to extend this code to work with ATAC
suva_expr = as.matrix(read.table("~/test.tsv",sep=" ",header=T,row.names=1,check.names=F))
suva_expr<-cpm(suva_expr,log = TRUE,prior.count=2)
suva_expr [which(is.na(suva_expr ))]=0
regions=read.table("~/CONICS-master/chromosome_arm_positions_grch38.txt",sep="\t",row.names = 1,header = T)
head(regions,n=5)
gene_pos=getGenePositions(rownames(suva_expr))
suva_expr
suva_expr=filterMatrix(suva_expr,gene_pos[,"hgnc_symbol"],minCells=5)
t(head(suva_expr))
normFactor=calcNormFactors(suva_expr)
l=plotAll(suva_expr,normFactor,regions,gene_pos,"AN_CNVs_log")
d
hi=plotHistogram(l,suva_expr,clusters=2,zscoreThreshold=4)
plotTsneProbabilities(ts,suva_expr,l[,"1p"],"Tsne Chr1p")
plotTsneProbabilities(ts,suva_expr,l[,"1p"],"Tsne Chr1p")
lrbic=read.table("AN_CNVs_log_BIC_LR.txt",sep="\t",header=T,row.names=1,check.names=F)
colnames(lrbic)
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>200 & lrbic[,"LRT adj. p-val"]<0.01)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>200 & lrbic[,"LRT adj. p-val"]<0.001)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>2000 & lrbic[,"LRT adj. p-val"]<0.001)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>500 & lrbic[,"LRT adj. p-val"]<0.001)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>400 & lrbic[,"LRT adj. p-val"]<0.001)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>400 & lrbic[,"LRT adj. p-val"]<0.01)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>300 & lrbic[,"LRT adj. p-val"]<0.01)]
candRegions
hi=plotHistogram(l[,candRegions],suva_expr,clusters=4,zscoreThreshold=4)
hi
normal= which(hi==1)
tumor=which(hi!=1)
tumor
hi
hclust(dist(hi,method="manhattan"),method="ward.D2")
clusts<-hclust(dist(hi,method="manhattan"),method="ward.D2")
clusts
cut(clusts,n=2)
cutree(clusts,n=2)
cutree(clusts,k=2)
cutree(clusts,k=2)
length(normal)
length(tumor)
candRegions
library(data.table)
meta<-fread("~/cnv_charts_from_divya/elementmetadata.tsv",header=TRUE,sep="\t")
meta
meta<-fread("~/cnv_charts_from_divya/elementmetadata.tsv",header=TRUE,sep=" ")
meta
meta<-fread("~/cnv_charts_from_divya/elementmetadata.tsv",sep=" ")
meta
data<-fread("~/cnv_charts_from_divya/genescore_p1.tsv",sep=" "
data<-fread("~/cnv_charts_from_divya/genescore_p1.tsv",sep=" ")
data<-fread("~/cnv_charts_from_divya/genescore_p1.tsv",sep=" ")
suva_expr
rownames(data)<-meta$name
data
data$`P1_R#GCTGAGCTCCTTACGC-1`
head(data$`P1_R#GCTGAGCTCCTTACGC-1`)
data
rownames(data)
head(suva_expr)
data_expr<-cpm(data,log = TRUE,prior.count=2)
data_expr[which(is.na(data_expr ))]=0
suva_expr<-data_expr
gene_pos=getGenePositions(rownames(suva_expr))
suva_expr
suva_expr=filterMatrix(suva_expr,gene_pos[,"hgnc_symbol"],minCells=5)
t(head(suva_expr))
normFactor=calcNormFactors(suva_expr)
l=plotAll(suva_expr,normFactor,regions,gene_pos,"AN_CNVs_log_divya")
suva_expr=filterMatrix(suva_expr,gene_pos[,"hgnc_symbol"],minCells=5)
gene_pos=getGenePositions(rownames(suva_expr))
data_expr
data_expr$V1
data_expr[,V1]
rownames(data)
data<-as.matrix(fread("~/cnv_charts_from_divya/genescore_p1.tsv",sep=" "))
rownames(data)<-meta$name
rownames(data)
head(data[,1:5])
data_expr<-cpm(data,log = TRUE,prior.count=2)
data_expr[which(is.na(data_expr ))]=0
suva_expr<-data_expr
gene_pos=getGenePositions(rownames(suva_expr))
suva_expr=filterMatrix(suva_expr,gene_pos[,"hgnc_symbol"],minCells=5)
normFactor=calcNormFactors(suva_expr)
l=plotAll(suva_expr,normFactor,regions,gene_pos,"AN_CNVs_log_divya")
hi=plotHistogram(l,suva_expr,clusters=2,zscoreThreshold=4)
plotTsneProbabilities(ts,suva_expr,l[,"1p"],"Tsne Chr1p")
#
lrbic=read.table("AN_CNVs_log_divya_BIC_LR.txt",sep="\t",header=T,row.names=1,check.names=F)
colnames(lrbic)
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>300 & lrbic[,"LRT adj. p-val"]<0.01)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>500 & lrbic[,"LRT adj. p-val"]<0.01)]
candRegions
candRegions=rownames(lrbic)[which(lrbic[,"BIC difference"]>1000 & lrbic[,"LRT adj. p-val"]<0.01)]
candRegions
hi=plotHistogram(l[,candRegions],suva_expr,clusters=4,zscoreThreshold=4)
l[,"1q"]
hist(l[,"1q"])
normal= which(hi==1)
length(normal)
tumor=which(hi!=1)
length(tumor)
library(Signac)
library(Seurat)
counts <- Read10X_h5("/Users/ananikolic/aGBM_scATAC_matrix/4349/raw_peak_bc_matrix.h5")
metadata <- read.csv(
file = "/Users/ananikolic/aGBM_scATAC_matrix/4349/singlecell.csv",
header = TRUE,
row.names = 1
)
metadata
#now add custom metadata fields
#https://satijalab.org/signac/articles/motif_vignette.html
pbmc <- CreateSeuratObject(
counts = counts,
assay = 'peaks',
project = 'ATAC',
min.cells = 1,
meta.data = metadata
)
fragment.path <- '/Users/ananikolic/aGBM_scATAC_newcellranger/4349/fragments.tsv.gz'
pbmc <- SetFragments(
object = pbmc,
file = fragment.path
)
pbmc
#initial QC step
pbmc <- NucleosomeSignal(object = pbmc)
pbmc$pct_reads_in_peaks <- pbmc$peak_region_fragments / pbmc$passed_filters * 100
pbmc$blacklist_ratio <- pbmc$blacklist_region_fragments / pbmc$peak_region_fragments
pbmc <- subset(
x = pbmc,
subset = peak_region_fragments > 3000 &
pct_reads_in_peaks > 15 &
blacklist_ratio < 0.05  #& lowmapq < 15000
)
set.seed(1234)
pbmc <- RunTFIDF(pbmc)
pbmc <- FindTopFeatures(pbmc, min.cutoff = 'q0')
pbmc@assays$peaks@var.features
pbmc <- RunSVD(
object = pbmc,
assay = 'peaks',
reduction.key = 'LSI_',
reduction.name = 'lsi'
)
##ADD METADATA
a<-read.csv("/Users/ananikolic/4349_merge_dm.csv",stringsAsFactors=FALSE,row.names=1,header=TRUE)
b<-read.csv("/Users/ananikolic/4349_5k_n_cov_2_nolog_test_sqrt2_cnv_anno_binary.csv",stringsAsFactors=FALSE,row.names=1,header=TRUE)
library(dplyr)
library(tibble)
#egfr<-a %>% select(chr7_49000000.chr7_86000000)
a2<-rownames_to_column(a,var="Cell")
a3<-left_join(data.frame(Cell=names(pbmc$cell_id)),a2,by="Cell")
pbmc$cell_id
b1<-left_join(data.frame(Cell=names(pbmc$cell_id)),rownames_to_column(b,var="Cell"),by="Cell")
pbmc <- RunUMAP(object = pbmc, reduction = 'lsi', dims = 2:30)
pbmc <- FindNeighbors(object = pbmc, reduction = 'lsi', dims = 2:30)
pbmc <- FindClusters(object = pbmc, verbose = FALSE, algorithm = 3)
plot1<-DimPlot(object = pbmc)
#SMOOTH DATA
b1c<-b1 %>% mutate(clust=pbmc$seurat_clusters)
#vars(starts_with("chr"))
#if_else(is.na(.),2L,.)
b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.))) %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>% mutate_at(vars(starts_with("chr")),funs(round(.,digits=0)))
b1c_round
library(data.table)
isMultiple<-function(x){if (max(x)==min(x)){
return(TRUE)
}
else
{
return(FALSE)
}}
b1c_round[,lapply(.SD,isMultiple),by="clust"]
b1c_round[,lapply(.SD,isMultiple)]
b1c_round
bb<-data.table(b1c_round)
bb[,lapply(.SD,isMultiple)]
isMultiple<-function(x){
x2<-as.numeric(x)
if (max(x2)==min(x2)){
return(TRUE)
}
else
{
return(FALSE)
}}
bb[,lapply(.SD,isMultiple)] #,by="clust"]
bb[,lapply(.SD,isMultiple)]==FALSE
which(bb[,lapply(.SD,isMultiple)]==FALSE)
bb[,which(bb[,lapply(.SD,isMultiple)]==FALSE)]
bb[which(bb[,lapply(.SD,isMultiple)]==FALSE)] #,by="clust"]
bb[,which(bb[,lapply(.SD,isMultiple)]==FALSE)] #,by="clust"]
bb[,colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]]
colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]
bb[,..colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]] #,by="clust"]
bb[,..colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]]
bb[,.SD,.SDcols=colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]]
smoothClusters <- function(inputClusterFile,inputCNVList,inputCNVClusterFile="",percentPositive=0.5,removeEmpty=TRUE)
{
inputClusters<-read.table(inputClusterFile,stringsAsFactors=FALSE,header=TRUE,sep=",")
colnames(inputClusters)[2]<-"clust"
inputCNV<-""
if (inputCNVClusterFile!="")
{
inputCNV<-read.table(inputCNVClusterFile,stringsAsFactors=FALSE,header=TRUE,sep=",")
inputCNV <- inputCNV %>% mutate_at(vars(starts_with("chr")),list(as.double))
#print(inputCNV
}
else
{
#input from CNV calls
inputCNV<-inputCNVList[[1]]
#colnames(inputCNV)[1]<-"Barcode"
}
colnames(inputCNV)[1]<-"Barcode"
#print(colnames(inputClusters))
#print(inputClusters$Barcode)
#colnames(inputClusters)[1]<-"Barcode"
#print(inputClusters[,1])
b1<-left_join(inputClusters,inputCNV,by="Barcode")
#SMOOTH
b1c<-b1 %>% mutate(clust=inputClusters[,2])
b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2,.))) %>%
group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>%
mutate_at(vars(starts_with("chr")),funs(round(. + (0.5 - percentPositive),digits=0)))
if (removeEmpty)
{
isMultiple<-function(x){
x2<-as.numeric(x)
if (max(x2)==min(x2)){
return(TRUE)
}
else
{
return(FALSE)
}}
bb<-data.table(b1c_round)
colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]
bb[,.SD,.SDcols=colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE)]]
b1c_round<-bb
}
cluster_clean<-left_join(inputClusters,b1c_round,by="clust")
return(cluster_clean)
}
library(scATACCNV)
initialiseEnvironment(genomeFile="/Users/ananikolic/aGBM_scATAC_newcellranger/4218/outs/chrom_sizes.tsv",
cytobandFile="~/hg38_bands_full.bed",
cpgFile="~/cpg_counts_hg38.bed",
binSize=1e6,
minFrags=1e4,
cellSuffix=c("-1","-2"),
lowerTrim=0.5,
upperTrim=0.8)
initializeStandards(chromSizeFile="/Users/ananikolic/aGBM_scATAC_newcellranger/4218/outs/chrom_sizes.tsv",
cytobandFile="~/hg38_bands_full.bed",
cpgDataFile="~/cpg_counts_hg38.bed")
library(data.table)
library(dplyr)
#inputFile="/Users/ananikolic/pGBM_ATAC_2/p7/1e6_5k_cov.tsv"
inputFile = "/Users/ananikolic/aGBM_scATAC_newcellranger/4218/1e6_5k_cov.tsv"
#scData2<-fread(inputFile,header=TRUE,stringsAsFactors = FALSE,sep="\t",data.table = FALSE)
#head(as_tibble(t(column_to_rownames(scData2,var="Cell_id"))) %>% select(ends_with(c("-2"))),n=1)
#easy way is to just provide a c of possible cell endings rather than hacking it (lazy person easiness)
#TODO: add this to the environmental variables
setOutputFile("~/","4218n")
scData<-readInputTable(inputFile)
scData
library(dplyr)
library(tibble)
#didn't work
library(compiler)
cutAverageC<-cmpfun(cutAverage)
summaryFunction<-cutAverageC
library("devtools")
setwd("~/scATAC_CNV_TOOL")
document()
library("devtools")
setwd("~/scATAC_CNV_TOOL")
document()
setwd("~")
install("scATAC_CNV_TOOL")
library(stringr)
#TEST CASE
#INITIALISE ENVIRONMENT
#scCNVCaller <- new.env()
#assign("scCNVCaller",new.env())
#http://adv-r.had.co.nz/Environments.html
#weirdly doesn't create this
initialiseEnvironment(genomeFile="/Users/ananikolic/aGBM_scATAC_newcellranger/4218/outs/chrom_sizes.tsv",
cytobandFile="~/hg38_bands_full.bed",
cpgFile="~/cpg_counts_hg38.bed",
binSize=1e6,
minFrags=1e4,
cellSuffix=c("-1","-2"),
lowerTrim=0.5,
upperTrim=0.8)
initializeStandards(chromSizeFile="/Users/ananikolic/aGBM_scATAC_newcellranger/4218/outs/chrom_sizes.tsv",
cytobandFile="~/hg38_bands_full.bed",
cpgDataFile="~/cpg_counts_hg38.bed")
library(data.table)
library(dplyr)
#inputFile="/Users/ananikolic/pGBM_ATAC_2/p7/1e6_5k_cov.tsv"
inputFile = "/Users/ananikolic/aGBM_scATAC_newcellranger/4218/1e6_5k_cov.tsv"
setOutputFile("~/","4218n")
scData<-readInputTable(inputFile)
scData
library(dplyr)
library(tibble)
#didn't work
library(compiler)
cutAverageC<-cmpfun(cutAverage)
summaryFunction<-cutAverageC
a1 = 5
b1 = 1
sc_t<-data.table(t(scData))
#sc_t
cellReads<-transpose(sc_t[,lapply(.SD,sum)],keep.names="Cell")
hist(cellReads$V1, breaks=30)
hist(cellReads$V1, breaks=30) + abline(quantile(cellReads$V1,0.95))
?abline
hist(cellReads$V1, breaks=30) + abline(v=quantile(cellReads$V1,0.95))
hist(cellReads$V1, breaks=30)
quantile(cellReads$V1,0.95)
str(quantile(cellReads$V1,0.95))
as.numeric(quantile(cellReads$V1,0.95)
as.numeric(quantile(cellReads$V1,0.95))
as.numeric(quantile(cellReads$V1,0.95))
hist(cellReads$V1, breaks=30) + abline(v=as.numeric(quantile(cellReads$V1,0.95)))
abline(v=as.numeric(quantile(cellReads$V1,0.95)))
abline(v=as.numeric(quantile(cellReads$V1,0.95)))
hist(cellReads$V1, breaks=30)
abline(v=quantile(cellReads$V1,0.95))
title("4218n")
dev.off()
title("4218n")
hist(cellReads$V1, breaks=30)
abline(v=quantile(cellReads$V1,0.95))
hist(cellReads$V1, breaks=30,title="4218n")
hist(cellReads$V1, breaks=30,main="4218n")
abline(v=quantile(cellReads$V1,0.95))
abline(v=quantile(cellReads$V1,0.95),color="red")
abline(v=quantile(cellReads$V1,0.95),col=c("red"))
source('~/packageTestCNV_4218.R', echo=TRUE)
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
dev.off()
hist(cellReads$V1, breaks=30,main="4218n")
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
hist(cellReads$V1, breaks=50,main="4218n")
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
hist(cellReads$V1, breaks=50,main="4218n",xlab = "Density")
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
hist(cellReads$V1, breaks=50,main="4218n",xlab = "Signal")
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
normalizeMatrixN <- function(inputMatrix,logNorm=FALSE,maxZero=500,imputeZeros=FALSE,blacklistProp=0.8, priorCount=1,blacklistCutoff=0,dividingFactor=1e6,upperFilterQuantile=0.95)
{
sc_t<-data.table(t(inputMatrix))
#sc_t
cellReads<-transpose(sc_t[,lapply(.SD,sum)],keep.names="Cell")
pdf(str_c(scCNVCaller$locPrefix,scCNVCaller$outPrefix,"_signal_distribution.pdf"),width=6,height=4)
hist(cellReads$V1, breaks=50,main=scCNVCaller$outPrefix,xlab = "Signal")
abline(v=quantile(cellReads$V1,0.95),col=c("red"),lty=2)
dev.off()
readsCells=cellReads[,mean(V1)]
#apply quantile filter
sc_t[,cellReads[cellReads[,V1>quantile(cellReads$V1,upperFilterQuantile)]]$Cell:=NULL]
nCells<-nrow(cellReads)
print(str_c("Total number of starting cells: ",nCells," Average reads per cell: ",mean(readsCells)))
scCNVCaller$meanReadsPerCell<-readsCells
blacklistPropCutoff=blacklistProp*nCells
#good
#find bad columns
sc_lines<-data.table(scData)
# head(sc_lines)
#blacklistCutoff = 500
sc_lines<-sc_lines[,lapply(.SD,function(x) x<blacklistCutoff)][,lapply(.SD,sum)]
sc_pos<-transpose(sc_lines,keep.names = "Pos")
blacklistRegions<-sc_pos[which(sc_pos[,V1>=blacklistPropCutoff]),]$Pos
print(length(blacklistRegions))
print(nrow(sc_pos))
if (length(blacklistRegions)==nrow(sc_pos))
{
print("Error: no regions meet cutoff criteria")
return(NULL)
}
sc_t2<-sc_t[which(sc_pos[,V1<blacklistPropCutoff]),lapply(.SD,function(x) as.numeric(x<blacklistCutoff))][,lapply(.SD,sum)]
print(sc_t[which(sc_pos[,V1<blacklistPropCutoff]),lapply(.SD,function(x) as.numeric(x<blacklistCutoff))][1:10,1:10])
#print(sc_t2[,1:100])
sc_zeros<-transpose(sc_t2,keep.names="Cells")
#print(sc_zeros)
#zero_cutoff=zero_cutoff
zero_list<-sc_zeros[which(sc_zeros[,V1<maxZero])]$Cells
zero_list
#print(zero_list)
#zeros<-rownames_to_column(tmp1,var="Chrom") %>% filter(!(Chrom %in% blacklistRegions$Chrom)) %>% summarise_if(is.numeric,funs(sum(.==0))) %>% gather(Cell,Value) %>% mutate(cellPass=(Value<maxZero))
scCNVCaller$cellsPassingFilter<-length(zero_list)
print(str_c(scCNVCaller$cellsPassingFilter, " cells passing filter"))
#get low confidence regions
#message(blacklistRegions$Chrom)
#hist(zeros$Value,breaks=100)
#zeros$Cell[zeros$cellPass==TRUE]
tmp1 <- as.data.frame(sc_t,stringsAsFactors=FALSE) %>% select(zero_list)
raw_medians<-t(transpose(sc_t[,..zero_list])[,lapply(.SD,median)])
#tmp1
tmp1<-cbind.data.frame(tmp1,raw_medians,stringsAsFactors=FALSE)
#impute zeros in cells passing filter
if (imputeZeros==TRUE)
{
tmp3 <- tmp1 %>% mutate_at(vars(ends_with(scCNVCaller$cellSuffix)),~ if_else(. == 0,raw_medians,.)) %>% select(-raw_medians)
}
else
{
tmp3 <- tmp1  # %>% select(-raw_medians)
}
#now normalize quantiles to account for differences in coverage
#scData_n<- normalize.quantiles(scData_t)
scData_n<-cpm(tmp3,log = logNorm,prior.count = priorCount)
rownames(scData_n)<-colnames(inputMatrix)
colnames(scData_n)<-colnames(tmp3)
#scData_n
head(scData_n)
#var_int<-apply(scData_n[1:nrow(scData_n),], 1, var, na.rm=TRUE)
#scData_nv<-cbind(scData_n,nvariance=var_int)
scData_nc_split <- rownames_to_column(as.data.frame(scData_n),var = "Loc") %>% mutate(blacklist=(Loc %in% blacklistRegions)) %>% separate(col=Loc,into=c("chrom","pos"))
scData_k<- scData_nc_split %>% mutate_at(vars(ends_with(scCNVCaller$cellSuffix)),funs(./ dividingFactor))
return(scData_k)
}
library("devtools")
setwd("~/scATAC_CNV_TOOL")
document()
