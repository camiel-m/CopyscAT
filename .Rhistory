#print(colnames(inputClusters))
#print(inputClusters$Barcode)
#colnames(inputClusters)[1]<-"Barcode"
#print(inputClusters[,1])
b1<-left_join(inputClusters,inputCNV,by="Barcode")
#SMOOTH
b1c<-b1 %>% mutate(clust=inputClusters[,2])
specRound <- function(x,boost=0.1)
{
#  print(x-2)
# print(sign(x-2)*round(abs(x-2)+boost))
#print(abs(x-2)+boost)
return (2+sign(x-2)*round(abs(x-2)+boost,digits=0))
}
#b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.)))
#b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.))) %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>% mutate_at(vars(starts_with("chr")),funs(specRound(.,boost=-0.1)))
b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2,.))) %>%
group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>%
mutate_at(vars(starts_with("chr")),funs(specRound(.,0.5 - percentPositive)))
if (removeEmpty)
{
isMultiple<-function(x){
x2<-as.numeric(x)
if (max(x2)==min(x2)){
return(TRUE)
}
else
{
return(FALSE)
}}
bb<-data.table(b1c_round)
# print(bb)
#print(colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE),.SDcols=colnames(bb)[which(str_detect(colnames(bb),"chr"))])
bb[,.SD,.SDcols=colnames(bb)[which(bb[,lapply(.SD,isMultiple),.SDcols=-c("clust")]==FALSE)]]
b1c_round<-bb
}
cluster_clean<-left_join(inputClusters,b1c_round,by="clust")
return(cluster_clean)
}
smoothedCNVList<-smoothClusters(scDataSampClusters,inputCNVList = final_cnv_list[[3]],percentPositive = 0.5,removeEmpty = FALSE)
smoothedCNVList
tail(smoothedCNVList)
#PART 3: identify double minutes / amplifications
#note: this is slow, and may take ~5 minutes
#if very large dataset, may run on subset of the data to estimate the amplifications in distinct clusters
#option to compile this code
library(compiler)
dmRead<-cmpfun(identifyDoubleMinutes)
#
#minThreshold is a time-saving option that doesn't call changepoints on any cell with a maximum Z score less than 4 - you can adjust this to adjust sensitivity of double minute calls (note - lower value = slower)
dm_candidates<-dmRead(scData_k_norm,minCells=100,qualityCutoff2 = 100,minThreshold = 4)
smoothedCNVList$chr7p
smoothedCNVList$chr7q
smoothedCNVList$chr10p
smoothedCNVList<-smoothClusters(scDataSampClusters,inputCNVList = final_cnv_list[[3]],percentPositive = 0.4,removeEmpty = FALSE)
tail(smoothedCNVList)
smoothedCNVList$chr10p
scDataSampClusters
final_cnv_list[[3]]
smoothedCNVList<-smoothClusters(scDataSampClusters,inputCNVList = final_cnv_list[[3]],percentPositive = 0.4,removeEmpty = FALSE)
smoothedCNVList$chr10p
smoothClusters <- function(inputClusters,inputCNVList,inputCNVClusterFile="",percentPositive=0.5,removeEmpty=TRUE)
{
#inputClusters<-read.table(inputClusterFile,stringsAsFactors=FALSE,header=TRUE,sep=",")
colnames(inputClusters)[2]<-"clust"
colnames(inputClusters)[1]<-"Barcode"
inputCNV<-""
if (inputCNVClusterFile!="")
{
inputCNV<-read.table(inputCNVClusterFile,stringsAsFactors=FALSE,header=TRUE,sep=",")
inputCNV <- inputCNV %>% mutate_at(vars(starts_with("chr")),list(as.double))
#print(inputCNV
}
else
{
#input from CNV calls
inputCNV<-inputCNVList
#colnames(inputCNV)[1]<-"Barcode"
}
colnames(inputCNV)[1]<-"Barcode"
#print(colnames(inputClusters))
#print(inputClusters$Barcode)
#colnames(inputClusters)[1]<-"Barcode"
#print(inputClusters[,1])
b1<-left_join(inputClusters,inputCNV,by="Barcode")
#SMOOTH
b1c<-b1 %>% mutate(clust=inputClusters[,2])
specRound <- function(x,boost=0.1)
{
#  print(x-2)
# print(sign(x-2)*round(abs(x-2)+boost))
#print(abs(x-2)+boost)
return (2+sign(x-2)*round(abs(x-2)+boost,digits=0))
}
#b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.)))
#b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.))) %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>% mutate_at(vars(starts_with("chr")),funs(specRound(.,boost=-0.1)))
b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2,.))) %>%
group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>%
mutate_at(vars(starts_with("chr")),funs(specRound(.,0.5 - percentPositive)))
print(b1c_round)
if (removeEmpty)
{
isMultiple<-function(x){
x2<-as.numeric(x)
if (max(x2)==min(x2)){
return(TRUE)
}
else
{
return(FALSE)
}}
bb<-data.table(b1c_round)
# print(bb)
#print(colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE),.SDcols=colnames(bb)[which(str_detect(colnames(bb),"chr"))])
bb[,.SD,.SDcols=colnames(bb)[which(bb[,lapply(.SD,isMultiple),.SDcols=-c("clust")]==FALSE)]]
b1c_round<-bb
}
cluster_clean<-left_join(inputClusters,b1c_round,by="clust")
return(cluster_clean)
}
smoothedCNVList<-smoothClusters(scDataSampClusters,inputCNVList = final_cnv_list[[3]],percentPositive = 0.4,removeEmpty = FALSE)
smoothClusters <- function(inputClusters,inputCNVList,inputCNVClusterFile="",percentPositive=0.5,removeEmpty=TRUE)
{
#inputClusters<-read.table(inputClusterFile,stringsAsFactors=FALSE,header=TRUE,sep=",")
colnames(inputClusters)[2]<-"clust"
colnames(inputClusters)[1]<-"Barcode"
inputCNV<-""
if (inputCNVClusterFile!="")
{
inputCNV<-read.table(inputCNVClusterFile,stringsAsFactors=FALSE,header=TRUE,sep=",")
inputCNV <- inputCNV %>% mutate_at(vars(starts_with("chr")),list(as.double))
#print(inputCNV
}
else
{
#input from CNV calls
inputCNV<-inputCNVList
#colnames(inputCNV)[1]<-"Barcode"
}
colnames(inputCNV)[1]<-"Barcode"
#print(colnames(inputClusters))
#print(inputClusters$Barcode)
#colnames(inputClusters)[1]<-"Barcode"
#print(inputClusters[,1])
b1<-left_join(inputClusters,inputCNV,by="Barcode")
#SMOOTH
print(b1)
b1c<-b1 %>% mutate(clust=inputClusters[,2])
print(b1c)
specRound <- function(x,boost=0.1)
{
#  print(x-2)
# print(sign(x-2)*round(abs(x-2)+boost))
#print(abs(x-2)+boost)
return (2+sign(x-2)*round(abs(x-2)+boost,digits=0))
}
#b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.)))
#b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2L,.))) %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>% mutate_at(vars(starts_with("chr")),funs(specRound(.,boost=-0.1)))
b1c_round<-b1c %>% mutate_at(vars(starts_with("chr")),funs(if_else(is.na(.),2,.))) %>%
group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean))  %>%
mutate_at(vars(starts_with("chr")),funs(specRound(.,0.5 - percentPositive)))
print(b1c_round)
if (removeEmpty)
{
isMultiple<-function(x){
x2<-as.numeric(x)
if (max(x2)==min(x2)){
return(TRUE)
}
else
{
return(FALSE)
}}
bb<-data.table(b1c_round)
# print(bb)
#print(colnames(bb)[which(bb[,lapply(.SD,isMultiple)]==FALSE),.SDcols=colnames(bb)[which(str_detect(colnames(bb),"chr"))])
bb[,.SD,.SDcols=colnames(bb)[which(bb[,lapply(.SD,isMultiple),.SDcols=-c("clust")]==FALSE)]]
b1c_round<-bb
}
cluster_clean<-left_join(inputClusters,b1c_round,by="clust")
return(cluster_clean)
}
smoothedCNVList<-smoothClusters(scDataSampClusters,inputCNVList = final_cnv_list[[3]],percentPositive = 0.4,removeEmpty = FALSE)
rownames(scDataSamp)
"TGGGTGCGTGAGTAAT-1" %in% rownames(scDataSamp)
"AGATAGAGTACGGAGT-1" %in% rownames(scDataSamp)
library(compiler)
dmRead<-cmpfun(identifyDoubleMinutes)
#
#minThreshold is a time-saving option that doesn't call changepoints on any cell with a maximum Z score less than 4 - you can adjust this to adjust sensitivity of double minute calls (note - lower value = slower)
dm_candidates<-dmRead(scData_k_norm,minCells=100,qualityCutoff2 = 100,minThreshold = 4)
dev.off()
dev.off()
dev.off()
dev.off()
dev.off()
library(Signac)
library(Seurat)
loadFile <- function(countsFile,fragmentFile,metadataFile)
{
#return chromatin assay
counts = Read10X_h5(filename=countsFile)
fragment.path= fragmentFile #"/Users/ananikolic/pGBM_ATAC_2/pGBM_2932/fragments.tsv.gz"
chrom_assay <- CreateChromatinAssay(
counts = counts,
genome = 'hg38',
sep = c(":","-"),
fragments = fragment.path,
#min.features = 10,
min.cells = 1
)
metadata <- read.csv(
file = metadataFile,
header = TRUE,
row.names = 1
)
tFile <- CreateSeuratObject(
counts = chrom_assay,
assay = "peaks", #,
meta.data = metadata,
min.cells = 10,
min.features = 10
)
return(tFile)
}
initNormalize <- function(mFile)
{
mFile <- NucleosomeSignal(object = mFile)
mFile$pct_reads_in_peaks <- mFile$peak_region_fragments / mFile$passed_filters * 100
mFile$blacklist_ratio <- mFile$blacklist_region_fragments / mFile$peak_region_fragments
mFile <- subset(
x = mFile,
subset = peak_region_fragments > 3000 &
pct_reads_in_peaks > 15 &
blacklist_ratio < 0.05  & lowmapq < 30000
)
return(mFile)
}
#let's try again with TFIDF after merge
#testing method 3 (default is 1)
initRegionalize <- function(mFile,assayType="peaks",doTFIDF=TRUE,dims=2:10)
{
if (doTFIDF)
{
mFile <- RunTFIDF(mFile,method=1)
}
mFile <- FindTopFeatures(mFile, min.cutoff = 'q5')
#mFile@assays$peaks@var.features
mFile <- RunSVD(
object = mFile,
assay = assayType,
reduction.key = 'LSI_',
reduction.name = 'lsi'
)
mFile <- RunUMAP(object = mFile, assay = assayType,reduction = 'lsi', dims = dims)
mFile <- FindNeighbors(object = mFile, assay = assayType, reduction = 'lsi', dims = dims,prune.SNN = 0.06,k.param=21) #,k.param = 71)
mFile <- FindClusters(object = mFile, assay = assayType, verbose = FALSE, algorithm = 3,n.start = 10,resolution = 0.5,group.singletons = FALSE)
return(mFile)
}
loadChromCNVOriginal <- function(cnvFile,atacFile,selSuffix="-1")
{
b<-read.csv(cnvFile,stringsAsFactors=FALSE,row.names=1,header=TRUE)
bb<-column_to_rownames(rownames_to_column(b,var="Cell") %>% dplyr::filter(str_detect(Cell,selSuffix)) %>% mutate(Cell=str_replace(Cell,"-2","-1")),var="Cell")
print(colnames(bb))
#b<-read.csv("~/SF11956_2_new22_cnv_scores.csv",stringsAsFactors=FALSE,row.names=1,header=TRUE)
#b<-read.csv("~/diaz_3_SF11956_2_nolog_test_new_cnv_anno_binary.csv",stringsAsFactors=FALSE,row.names=1,header=TRUE)
#names(atac_file$orig.ident)
b1<-left_join(data.frame(Cell=names(atacFile$orig.ident)),rownames_to_column(bb,var="Cell"),by="Cell")
#SMOOTH
atacFile<-AddMetaData(atacFile,column_to_rownames(b1,var="Cell"))
return(atacFile)
}
loadChromCNV <- function(cnvFile,atacFile,selSuffix="-1")
{
b<-read.csv(cnvFile,stringsAsFactors=FALSE,row.names=1,header=TRUE)
bb<-column_to_rownames(rownames_to_column(b,var="Cell") %>% dplyr::filter(str_detect(Cell,selSuffix)) %>% mutate(Cell=str_replace(Cell,"-2","-1")),var="Cell")
#b<-read.csv("~/SF11956_2_new22_cnv_scores.csv",stringsAsFactors=FALSE,row.names=1,header=TRUE)
#b<-read.csv("~/diaz_3_SF11956_2_nolog_test_new_cnv_anno_binary.csv",stringsAsFactors=FALSE,row.names=1,header=TRUE)
#names(atac_file$orig.ident)
b1<-left_join(data.frame(Cell=names(atacFile$seurat_clusters)),rownames_to_column(bb,var="Cell"),by="Cell")
#SMOOTH
print(b1)
b1c<-b1 %>% mutate(clust=atacFile$seurat_clusters)
specRound <- function(x,boost=0.1)
{
#  print(x-2)
# print(sign(x-2)*round(abs(x-2)+boost))
#print(abs(x-2)+boost)
return (2+sign(x-2)*round(abs(x-2)+boost,digits=0))
}
b1c_round<-b1c %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean),na.rm=TRUE)  %>% mutate_at(vars(starts_with("chr")),funs(specRound(.,boost=-0.10)))
cluster_clean<-left_join(data.frame(clust=atacFile$seurat_clusters),b1c_round,by="clust")
rownames(cluster_clean)=names(atacFile$seurat_clusters)
atacFile<-AddMetaData(atacFile,cluster_clean)
return(atacFile)
}
prettyPlot <- function(mFile,chromList,plotPrefix,sampPrefixA,legendPrefixX=0.20,legendPrefixY=0.25)
{
library(extrafont)
pdf(file=sprintf(plotPrefix,sampPrefixA),width=3.0,height=2.5)
for (chrom in chromList) {
#barcode list = names(atac_file$orig.ident)
list_of_vals<-levels(factor(round(unlist(mFile@meta.data[,chrom]),digits = 1)))
mFile <- AddMetaData(mFile,factor(round(mFile@meta.data[,chrom],digits=1),levels=c(list_of_vals,"NA")),"tmpchrom")
mFile$tmpchrom[which(is.na(mFile$tmpchrom))]<-"NA"
# print(pbmc@meta.data["tmpchrom"])
plot1<-DimPlot(object = mFile,group.by = c("tmpchrom"),pt.size=0.3)+ggtitle(chrom) + #+NoLegend() +
scale_color_brewer(type = "qual",palette = "Paired",drop=FALSE) +
theme(axis.text = element_text(size=10,family="Arial"),axis.title = element_text(size=10,family="Arial"),title = element_text(size=10,face = "plain",family="Arial"))
#legend.direction = "vertical",legend.box.just = "right",legend.position = c(legendPrefixX,legendPrefixY))
print(plot1)
}
#colnames(b)
dev.off()
}
prettyPlotCluster <- function(mFile,plotPrefix,sampPrefixA,clusterID="seurat_clusters")
{
library(extrafont)
pdf(sprintf(plotPrefix,sampPrefixA),width=2.5,height=2.5)
plot1<-DimPlot(object = mFile,pt.size=0.3,group.by=clusterID) +
scale_color_brewer(type = "qual",palette = "Paired",drop=FALSE) +
theme(axis.text = element_text(size=10,family="Arial"),axis.title = element_text(size=10,family="Arial"),title = element_text(size=10,face = "plain",family="Arial"))
print(plot1)
dev.off()
}
smoothChromCNV <- function(atacFile,boostVal=-0.1,sigDig=0)
{
chroms_i<-colnames(atacFile@meta.data)[which(str_detect(colnames(atacFile@meta.data),"chr[0-9]+[pq]"))]
b1c<-rownames_to_column(data.frame(atacFile@meta.data[c(chroms_i,"seurat_clusters")]),var="Cell") %>% mutate(clust=seurat_clusters) %>% dplyr::select(-seurat_clusters)
#SMOOTH
print(b1c)
specRound <- function(x,boost=0.1,sigDig=0)
{
#  print(x-2)
# print(sign(x-2)*round(abs(x-2)+boost))
#print(abs(x-2)+boost)
return (2+sign(x-2)*round(abs(x-2)+boost,digits=sigDig))
}
b1c_round<-b1c %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean),na.rm=TRUE)  %>% mutate_at(vars(starts_with("chr")),funs(specRound(.,boost=boostVal,sigDig=sigDig)))
cluster_clean<-left_join(data.frame(clust=atacFile$seurat_clusters),b1c_round,by="clust")
rownames(cluster_clean)=names(atacFile$seurat_clusters)
atacFile<-AddMetaData(atacFile,cluster_clean)
return(atacFile)
}
smoothChromCNVAmp <- function(atacFile,boostVal=0.1,sigDig=0)
{
chroms_i<-colnames(atacFile@meta.data)[which(str_detect(colnames(atacFile@meta.data),"chr[0-9]+_"))]
b1c<-rownames_to_column(data.frame(atacFile@meta.data[c(chroms_i,"seurat_clusters")]),var="Cell") %>% mutate(clust=seurat_clusters) %>% dplyr::select(-seurat_clusters)
#SMOOTH
print(b1c)
specRound <- function(x,boost=0.1,sigDig=0)
{
#  print(x-2)
# print(sign(x-2)*round(abs(x-2)+boost))
#print(abs(x-2)+boost)
return (sign(x)*round(abs(x)+boost,digits=sigDig))
}
b1c_round<-b1c %>% group_by(clust) %>% summarise_at(vars(starts_with("chr")),list(mean),na.rm=TRUE)  %>% mutate_at(vars(starts_with("chr")),funs(specRound(.,boost=boostVal,sigDig=sigDig)))
cluster_clean<-left_join(data.frame(clust=atacFile$seurat_clusters),b1c_round,by="clust")
rownames(cluster_clean)=names(atacFile$seurat_clusters)
atacFile<-AddMetaData(atacFile,cluster_clean)
return(atacFile)
}
library(tibble)
library(dplyr)
library(stringr)
#MOTIF INITIALIZATION
library(JASPAR2020)
library(TFBSTools)
library(BSgenome.Hsapiens.UCSC.hg38)
#ADD MOTIF ANALYSIS HERE
pfm <- getMatrixSet(
x = JASPAR2020,
opts = list(species = 9606, all_versions = FALSE)
)
comparePeaksToRandom <- function(dataFile)
{
all_peaks_list<-rownames(dataFile@assays$peaks@meta.features %>% dplyr::filter(count>200))
random_peaks<-all_peaks_list[floor(runif(2000,min=1,max=length(all_peaks_list)))]
asdf_random<-data.frame(chroms=sapply(random_peaks,str_extract,"chr[0-9XYM]+"))
asdf_random<-asdf_random %>% group_by(chroms) %>% summarise(counts_ran=n())
asdf_nn<-head(data.frame(chroms=sapply(dataFile@assays$peaks@var.features,str_extract,"chr[0-9XYM]+")),n=2000)
asdf_nn<-asdf_nn %>% group_by(chroms) %>% summarise(counts_new=n())
joined_list_chrom_peaks<-left_join(asdf_random,asdf_nn,"chroms")
joined_list_chrom_peaks$counts_new[is.na(joined_list_chrom_peaks$counts_new)]<-0
library(MASS)
library(tibble)
library(tidyr)
length(joined_list_chrom_peaks$chroms)
print(chisq.test(column_to_rownames(joined_list_chrom_peaks[1:21,] %>% dplyr::filter(counts_new!=0),var="chroms")))
print(ggplot(joined_list_chrom_peaks %>% gather(type,count,2:3)) + geom_col(aes(chroms,count,fill=type),stat="identity",position=position_dodge()) +
theme(panel.background = element_rect(fill="white"),
text = element_text(size=10,color="black"),
axis.text.x = element_text(angle=90,vjust = 0.5,hjust=1),
axis.line = element_line(color="black")))
}
configMotifs<-function(target_matrix)
{
#MOTIF ANALYSIS
library(motifmatchr)
print(target_matrix)
motif.matrix <- CreateMotifMatrix(
features = granges(target_matrix[["peaks"]]),
pwm = pfm,
genome = 'hg38',
use.counts = FALSE
)
motif <- CreateMotifObject(
data = motif.matrix,
pwm = pfm
)
#pbmc[["peaks"]]
#pbmc <- SetAssayData(object=pbmc,assay='peaks',slot='motifs',new.data=motif)
target_matrix <- SetAssayData(object=target_matrix,assay='peaks',slot='motifs',new.data=motif)
#region stats
target_matrix[["peaks"]] <- RegionStats(
object = target_matrix[["peaks"]],
genome = BSgenome.Hsapiens.UCSC.hg38,
sep = c(":", "-")
)
return(target_matrix)
}
#pbmc<-loadFile(countsFile = "/Users/ananikolic/aGBM_scATAC_matrix/4349/raw_peak_bc_matrix.h5",metadataFile ="/Users/ananikolic/aGBM_scATAC_matrix/4349/singlecell.csv",fragmentFile = '/Users/ananikolic/aGBM_scATAC_newcellranger/4349/fragments.tsv.gz')
#pbmc<-loadChromCNVOriginal(cnvFile = "~/cnv_samples_sept7_backup/4349nnewblah_90percent_3_cnv_scores.csv",atacFile=pbmc)
#pbmc<-loadChromCNVOriginal(cnvFile = "~/cnv_samples_sept7_backup/4349_5k_n_merge_dm.csv",atacFile=pbmc)
sampPrefixName="4250_new"
pbmc<-loadFile(countsFile = "/Users/ananikolic/aGBM_scATAC_matrix/4250/raw_peak_bc_matrix.h5",metadataFile ="/Users/ananikolic/aGBM_scATAC_matrix/4250/singlecell.csv",fragmentFile = '/Users/ananikolic/aGBM_scATAC_newcellranger/4250/fragments.tsv.gz')
pbmc<-loadChromCNVOriginal(cnvFile = "~/cnv_samples_sept7_backup/4250n2newblah_90percent_3_cnv_scores.csv",atacFile=pbmc)
pbmc<-loadChromCNVOriginal(cnvFile = "~/aGBM_scATAC_individual/4250_dm_new.csv",atacFile=pbmc)
pbmc<-initNormalize(pbmc)
pbmc<-initRegionalize(pbmc,doTFIDF = TRUE,dims=2:20)
pbmc$seurat_clusters
rownames(scDataSamp)
scDataSampClusters
scDataSampClusters$Barcode
haed(scDataSampClusters$Barcode)
head(scDataSampClusters$Barcode)
head(rownames(scDataSamp))
rownames(scDataSamp)
rownames(scDataSamp) %>% arrange()
data.frame(bc1=rownames(scDataSamp)) %>% arrange()
data.frame(bc1=rownames(scDataSamp)) %>% arrange(desc())
data.frame(bc1=rownames(scDataSamp)) %>% arrange(b1)
data.frame(bc1=rownames(scDataSamp)) %>% arrange(bc1)
head(scDataSampClusters %>% arrange(Barcode) %>% select(Barcode))
scDataSampClusters %>% arrange(Barcode)
scDataSampClusters %>% arrange(Barcode) %>% select(Barcode)
scDataSampClusters %>% arrange(Barcode) %>% dplyr::select(Barcode)
head(scDataSampClusters %>% arrange(Barcode) %>% dplyr::select(Barcode))
head(data.frame(bc1=rownames(scDataSamp)) %>% arrange(bc1))
data.frame(Barcode=rownames(scDataSamp)
data.frame(Barcode=rownames(scDataSamp))
pbmc
DimPlot(pbmc)
pbmc$seurat_clusters
pbmc<-initRegionalize(pbmc,doTFIDF = TRUE,dims=2:20)
DimPlot(pbmc)
pbmc$seurat_clusters
scDataSampClusters$pbmc.seurat_clusters
pbmc$seurat_clusters
scDataSampClusters<-pbmc$seurat_clusters
scDataSampClusters<-rownames_to_column(data.frame(pbmc$seurat_clusters),var="Barcode")
usethis::use_data(scDataSampClusters)
usethis::use_data(scDataSampClusters,overwrite=TRUE)
library("devtools")
setwd("~/scATAC_CNV_TOOL")
document()
install("~/scATAC_CNV_TOOL")
library(CopyscAT)
initialiseEnvironment(genomeFile="~/hg38_chrom_sizes.tsv",
cytobandFile="~/hg38_1e+06_cytoband_densities_granges.tsv",
cpgFile="~/hg38_1e+06_cpg_densities.tsv",
binSize=1e6,
minFrags=1e4,
cellSuffix=c("-1","-2"),
lowerTrim=0.5,
upperTrim=0.8)
#for this tutorial we will use the sample data included in scData
#to create your own use the process_fragment_file.py script included in the package and run it on a fragments.tsv.gz file of your choosing
setOutputFile("~","samp_dataset")
#PART 1: INITIAL DATA NORMALIZATION
#step 1 normalize the matrix
#USING SAMPLE DATA FROM PACKAGE
#option: if using your own file replace below with the following
#scData<-readInputTable("myInputFile.tsv")
scData<-scDataSamp
scData_k_norm <- normalizeMatrixN(scData,logNorm = FALSE,maxZero=2000,imputeZeros = FALSE,blacklistProp = 0.8,blacklistCutoff=125,dividingFactor=1,upperFilterQuantile = 0.95)
#when using your own data, please make sure you don't have any excess / alt chromosomes
#collapse into chromosome arm level
summaryFunction<-cutAverage
scData_collapse<-collapseChrom3N(scData_k_norm,summaryFunction=summaryFunction,binExpand = 1,minimumChromValue = 100,logTrans = FALSE,tssEnrich = 1,logBase=2,minCPG=300,powVal=0.73)
#apply additional filters
scData_collapse<-filterCells(scData_collapse,minimumSegments = 40,minDensity = 0.1)
#show unscaled chromosome list
graphCNVDistribution(scData_collapse,outputSuffix = "test_violinsn2")
#compute centers
median_iqr <- computeCenters(scData_collapse,summaryFunction=summaryFunction)
#PART 2: ASSESSMENT OF CHROMOSOME-LEVEL CNVs
#OPTION 1: identify chromosome-level amplifications using all cells to generate 'normal' control
#identify chromosome-level amplifications
candidate_cnvs<-identifyCNVClusters(scData_collapse,median_iqr,useDummyCells = TRUE,propDummy=0.25,minMix=0.01,deltaMean = 0.03,deltaBIC2 = 0.25,bicMinimum = 0.1, subsetSize=600,fakeCellSD = 0.08, uncertaintyCutoff = 0.55,summaryFunction=summaryFunction,maxClust = 4,mergeCutoff = 3,IQRCutoff= 0.2,medianQuantileCutoff = 0.4)
#cleanup step
candidate_cnvs_clean<-clusterCNV(initialResultList = candidate_cnvs,medianIQR = candidate_cnvs[[3]],minDiff=1.5) #= 1.5)
#final results and annotation
final_cnv_list<-annotateCNV4(candidate_cnvs_clean, saveOutput=TRUE,outputSuffix = "clean_cnv",sdCNV = 0.5,filterResults=TRUE,filterRange=0.8)
smoothedCNVList<-smoothClusters(scDataSampClusters,inputCNVList = final_cnv_list[[3]],percentPositive = 0.4,removeEmpty = FALSE)
tail(smoothedCNVList)
barcodeCycling<-estimateCellCycleFraction(scData,sampName="sample",cutoff=1000)
barcodeCycling
write.table(barcodeCycling[order(names(barcodeCycling))]==max(barcodeCycling),file=str_c(scCNVCaller$locPrefix,"_cycling_cells.tsv"),sep="\t",quote=FALSE,row.names=TRUE,col.names=FALSE)
scCNVCaller$locPrefix
write.table(barcodeCycling[order(names(barcodeCycling))]==max(barcodeCycling),file=str_c(scCNVCaller$locPrefix,scCNVCaller$outPrefix,"_cycling_cells.tsv"),sep="\t",quote=FALSE,row.names=TRUE,col.names=FALSE)
